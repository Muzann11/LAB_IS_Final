{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2eece3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modul\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.common.exceptions import StaleElementReferenceException, ElementClickInterceptedException\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Setup Firefox\n",
    "options = Options()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "driver = webdriver.Firefox(options=options)\n",
    "\n",
    "# List Kategori\n",
    "labels = [\n",
    "       'Accountant', 'Advocate', 'Agriculture', 'Apparel', 'Architecture',\n",
    "       'Arts', 'Automobile', 'Aviation', 'Banking', 'BPO',\n",
    "       'Building and Construction', 'Business Analyst', 'Civil Engineer',\n",
    "       'Consultant', 'Data Science', 'Database', 'Designing',\n",
    "       'Digital Media', 'DotNet Developer', 'Education',\n",
    "       'Electrical Engineering', 'Finance',\n",
    "       'Food and Beverages', 'Health and Fitness', 'Human Resources',\n",
    "       'Information Technology', 'Java Developer', 'Management',\n",
    "       'Network Security Engineer',\n",
    "       'Operations Manager', 'PMO', 'Public Relations',\n",
    "       'Python Developer', 'React Developer', 'Sales', 'SAP Developer',\n",
    "       'SQL Developer', 'Testing', 'Web Designing'\n",
    "]\n",
    "\n",
    "all_jobs = []  # untuk menyimpan hasil dari semua kategori\n",
    "\n",
    "# Loop untuk setiap label\n",
    "for label in labels:\n",
    "    print(f\"\\nScraping kategori: {label}\")\n",
    "\n",
    "    job_list = []\n",
    "    seen_ids = set()\n",
    "\n",
    "    # Buka halaman utama untuk kategori ini\n",
    "    url = f\"https://www.linkedin.com/jobs/search/?geoId=102478259&keywords={label.replace(' ', '%20')}\"\n",
    "    driver.get(url)\n",
    "    time.sleep(8)\n",
    "    # Scroll dan load sampai habis\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    stagnant_scrolls = 0\n",
    "\n",
    "    while True:\n",
    "        # Scroll ke bawah untuk memicu lazy load\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(3)\n",
    "\n",
    "        # Klik tombol See more jobs jika ada\n",
    "        try:\n",
    "            see_more_bottons = driver.find_elements(By.XPATH, \"//button[contains(., 'See more jobs')]\")\n",
    "            for btn in see_more_bottons:\n",
    "                try:\n",
    "                    driver.execute_script(\"arguments[0].click();\", btn)\n",
    "                    print(\"Klik See more jobs\")\n",
    "                    time.sleep(2)\n",
    "                except ElementClickInterceptedException:\n",
    "                    pass\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # Cek apakah halaman sudah tidak bertambah tinggi\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            stagnant_scrolls += 1\n",
    "        else:\n",
    "            stagnant_scrolls = 0\n",
    "        last_height = new_height\n",
    "\n",
    "        # Jika sudah mentok (tidak berubah 2 kali berturut-turut)\n",
    "        if stagnant_scrolls >= 2:\n",
    "            print(\"Sudah mencapai akhir halaman.\")\n",
    "            break\n",
    "\n",
    "    # Mengambil semua job card\n",
    "    job_cards = driver.find_elements(By.CSS_SELECTOR, \".base-card, .job-card-container\")\n",
    "    print(f\"Total job card ditemukan: {len(job_cards)}\")\n",
    "\n",
    "    for job in job_cards:\n",
    "        try:\n",
    "            job_id = job.get_attribute(\"data-entity-urn\") or job.get_attribute(\"data-job-id\")\n",
    "            if not job_id or job_id in seen_ids:\n",
    "                continue\n",
    "            seen_ids.add(job_id)\n",
    "\n",
    "            title = job.find_element(By.CSS_SELECTOR, \"h3\").text.strip()\n",
    "            company = job.find_element(By.CSS_SELECTOR, \"h4\").text.strip()\n",
    "            location = job.find_element(By.CLASS_NAME, \"job-search-card__location\").text.strip()\n",
    "            date = job.find_element(By.CSS_SELECTOR, \"time\").get_attribute(\"datetime\")\n",
    "\n",
    "            job_list.append([job_id, title, company, location, date, label])\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    print(f\"Total job tersimpan untuk '{label}': {len(job_list)}\")\n",
    "    all_jobs.extend(job_list)\n",
    "\n",
    "df = pd.DataFrame(all_jobs, columns=[\"job_id\", \"Title\", \"Company\", \"Location\", \"Date\", \"Category\"])\n",
    "df.drop_duplicates(subset=[\"job_id\"], keep=\"first\", inplace=True)\n",
    "\n",
    "# Simpan file\n",
    "OUTPUT_FILE_PATH = 'C:/Users/Acer/Trend Job/trend_job_list.csv' \n",
    "df.to_csv(OUTPUT_FILE_PATH, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"\\nSelesai scraping semua label!\")\n",
    "print(f\"File tersimpan di: {OUTPUT_FILE_PATH}\")\n",
    "print(f\"Total data unik tersimpan: {len(df)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
